\documentclass[../informe2.tex]{subfiles}
\begin{document}
En el presente informe se ha realizado una descripción en detalle del \mrp, con una revisión de la literatura referente a las distintos algoritmos y técnicas desarrollados para la resolución del problema, considerando las metaheurísticas y representaciones utilizadas para aquello. Además, se presentó una implementación propia basada en dos algoritmos, \greedy\ y \hillc, mostrando evidencia experimental de su funcionamiento. \par
\noindent Cabe destacar que a pesar de lo novel del problema -publicado en la ROADEF/EURO 2012-, la naturaleza o estructura de éste no es algo nuevo en la investigación científica, puesto que el \mrp\  puede considerarse como una versión más restringida del \textit{Generalized Assignment Problem} o del \textit{Bin Packing Problem}. Sin embargo, dado el contexto actual, en que los \textit{data centers} son piedras angulares en el funcionamiento de las organizaciones modernas y dado que su gestión se vuelve una tarea súmamente crítica en la búsqueda de la efectividad y eficiencia, el \mrp\ por sí solo adquiere una relevancia importante. El hecho de que haya sido planteado por Google, corporación que basa la provisión de sus servicios a través del funcionamiento de extensas \textit{granjas} de servidores, es un indicativo de que para la industria de la ``nube'', los objetivos planteados por el  \mrp\ son críticos. \par
\noindent Respecto de las técnicas de resolución vistas en la sección~\ref{sec:estado}, todas intentan solucionar el problema original publicado por Google. En general, dado que la presentación del problema se puede dar a través de instancias de gran tamaño, considerando por ejemplo 5000 máquinas, 50000 procesos y 12 recursos (descripción bastante cercana de la realidad que afrontan los gigantes informáticos), los algoritmos presentados utilizan esquemas de búsqueda local, que se aplican de forma iterativa sobre problemas de menor tamaño que el original, obtenidos a partir de un subconjunto de las máquinas y procesos involucrados, tratando de buscar asignaciones factibles y de bajo costo. A esto se suma que, el desafío original imponía un tiempo límite de ejecución para encontrar una solución de cinco minutos, por lo que los algoritmos en cuestión deben ser rápidos en la entrega de resultados. Lo anterior hace que la utilización técnicas completas de búsqueda quede totalmente descartada. \par
\noindent Bajo esa misma lógica, se implementó un algoritmo híbrido de dos partes. En la primera, se creó un algoritmo basado en una heurística \greedy, para ser utilizado en la generación de una solución inicial factible, alterna a la provista en las distintas instancias del problema~\ref{tabla:seta} y usadas en la \roadef. La heurística es simple y se basa en asignar primero, los procesos menos restringidos a las máquinas donde se produzca el menor costo de carga. Sin embargo, su efectividad para crear soluciones iniciales fue mínima (con éxito en una sola instancia), ya que un subconjunto de procesos se quedaba sin asignación debido a dos razones: los procesos que conseguían ser asignados quedaban mal distribuidos, por lo que no le dejaban ``espacio'' al resto, en términos de la capacidad disponible en las máquinas; y porque entre los servicios, no se satisfacían las relaciones de dependencia, especialmente cuando esas relaciones se concentraban en forma cerrada en un subconjunto de los servicios. Dado la baja efectividad y considerando que en el \mrp\ por definición se provee de una solución inicial factible, se tuvo que prescindir del \greedy\ para así poder generar resultados tangibles y comparables. \par
\noindent Es así como se pasa a la segunda parte del algoritmo, el \hillc. Utilizando como soluciones iniciales las entregadas en la \roadef, se genera el vecindario completo de soluciones en función del \textit{shift} de un proceso, escogiendo la nueva solución que genere la mayor disminución del costo total (\textit{mejor mejora}). Los experimentos mostraron que el \hillc, a pesar de estar fundamentado en una heurística simple, generó buenos resultados en la disminución de los costos totales utilizando muy poco tiempo, especialmente en las instancias más pequeñas (bajo el minuto~\ref{tabla:hc-comparative}). Características que favorecieron esta eficiencia fueron: representar las soluciones vecinas en función de las máquinas candidatas para realizar el \textit{shift} de un proceso y no generando un nuevo vector completo de asignaciones; evaluar la calidad de un \textit{shift}, en función de la variación del costo total y no en el cálculo de este desde cero para cada una de las soluciones vecinas; utilizar un lenguaje de programación como C++, altamente flexible (uso de punteros), con una enorme biblioteca de funciones y con la posibilidad de usar programación orientada a objetos para estructurar ordenadamente la aplicación. \par
\noindent También en relación al \hillc, se compararon dos estrategias para seleccionar los procesos candidatos a ser reasignados. Los experimentos muestraron que ordenar los procesos de acuerdo a su tamaño (suma de todos sus requerimientos) y reasignar los más grandes primero, hace que se consigan mejores resultados, hecho concordante con otras investigaciones relativas al tema~\cite{gavranovicefficient}. Mejoras en la implementación del \hillc, involucran la utilización de otros movimientos generadores de soluciones vecinas, tales como el \textit{swap}, que en teoría ofrecen un mayor nivel de exploración del espacio de búsqueda. \par
\noindent En relación al trabajo futuro en torno al \mrp, es destacable las mejoras que puede proveer la utilización de múltiples procesadores a la hora de ejecutar los distintos algoritmos. La implementación presentada en este informe es \textit{single thread}. También sería importante pensar en la configuración automática y en tiempo real de los distintos parámetros de entrada que necesitan los algoritmos para ejecutarse, como por ejemplo la proporción de máquinas que se utilizarán para crear un subproblema.

\end{document}
