\documentclass[../informe2.tex]{subfiles}
\begin{document}
%La información que describen en este punto se basa en los estudios realizados con antelación respecto al tema.
%Lo más importante que se ha hecho hasta ahora con relación al problema. Debería responder preguntas como las siguientes:
%cuándo surge?, qué métodos se han usado para resolverlo?, cuáles son los mejores algoritmos que se han creado hasta
%la fecha?, qué representaciones han tenido los mejores resultados?, cuál es la tendencia actual para resolver el problema?, tipos de movimientos, heurísticas, métodos completos, tendencias, etc... Puede incluir gráficos comparativos o explicativos.\\

El \mrp\ fue publicado como parte de la ROADEF/EURO del año 2012, en colaboración con Google, desafío en el cual participaron diferentes equipos de todo el mundo. El desafío propiamente tal tuvo instancias de evaluación, consistentes en problemas que iban desde un tamaño pequeño (4 máquinas, 100 procesos y 2 recursos), hasta problemas cercanos a un escenario real, como el que se puede apreciar en los data centers de las grandes corporaciones (5000 máquinas, 50000 procesos, 12 recursos). El tiempo máximo de ejecución de los algoritmos para cada instancia era de 5 minutos. Se comenzaba desde una solución inicial factible, generada aleatoriamente.  \\
Considerando las anteriores condiciones, el desarrollo de las distintas técnicas de solución se han basado en metaheurísticas que tienen en su core, procedimientos de búsqueda local que se aplican iterativamente, tratando de obtener una asignación de menor costo en cada repetición. Comúnmente se opera solo con un subconjunto de las máquinas y procesos, debido especialmente al gran tamaño de algunas instancias del problema, las cuales son las que presentan mayor relación con la realidad de las grandes corporaciones como Google. Dada la naturaleza de la búsqueda local, la generación de los vecindarios de soluciones se originan, principalmente, en base a dos tipos de movimientos: \textit{shift}, que implica trasladar un proceso de una máquina a otra; y el de \textit{swap}, que implica el intercambio de la asignación de las máquinas distintas de dos procesos. Algunas de las técnicas a ver, incorporan mecanismos de perturbación, que modifican de forma aleatoria partes de la solución actual, con el fin incorporar más zonas del espacio de búsqueda. Otras incorporan técnicas de reinicio, para escapar de óptimos locales. En general (especialmente con grandes instancias), para evaluar la calidad de una solución, se hace en base a la comparación con los llamados \textit{lower bounds} o límites inferiores, especialmente respecto de los costos de carga y de balance, que por lo que puede desprenderse de la literatura, se consideran los más importantes.\\
A continuación se presentan los trabajos más importante desarrollados hasta la fecha, en función de la resolución del \mrp. Se nombraran algunas metaheurísticas notables que han sido utilizadas, proveyendo una pequeña definición de cada una.

\subsubsection{Large Neighborhood Search}
La metaheurística Large Neighborhood Search (LNS), fue propuesta en 1998 por Shaw \cite{shaw1998using}. En LNS, se mejora una solución inicial de forma gradual, destruyendo y reparando alternadamente la solución.\\
Consiguiendo el segundo lugar en la ROADEF/EURO del año 2012, Mehta et al. \cite{mehta2012comparing}, proponen dos soluciones. Una primera, utilizando un modelo basado en Mixed Integer Linear Programming (MIP); una segunda basada en Constraint Programming (CP). En ambos casos, se utilizó la metaheurística LNS para la búsqueda de la solución. En cada iteración del LNS, se selecciona un subconjunto de máquinas. Desde estas últimas, se escoge un conjunto de procesos. Se forma así, un subproblema de tamaño más pequeño que el original, para luego ser optimizado y obtener una asignación que mejore la inicial.
En \cite{mehta2012comparing}, los resultados muestran que las soluciones obtenidas por el algoritmo basado en CP, superan a las obtenidas por la versión MIP, escalando mejor para problemas de mayor envergadura, con un consumo de memoria menor y con una mejor calidad en las soluciones. Se deja entrever que el uso de computadores con múltiples núcleos, puede mejorar el rendimiento de los algoritmos. Posteriormente, los mismo autores en \cite{malitsky2013tuning} desarrollan métodos automáticos para la generación de parámetros de entrada para el LNS, para así mejorar la performance de este último. Entre esos parámetros se encuentran el número máximo de procesos que pueden ser seleccionados de una máquina para ser reasignados, el máximo del total de procesos que pueden ser seleccionados para ser reasignados, el máximo de máquinas que se seleccionan para crear un subproblema, entre otros. Las pruebas muestran que los resultados son positivos a la hora de obtener mejores asignaciones, a pesar del costo computacional adicional que implica el ejecutar estos métodos automáticos, aunque se ve rápidamente solventado cuando se considera un espectro de tiempo más amplio. \\

\subsubsection{Variable Neighborhood Search}
La metaheurística Variable Neighborhood Search (VNS), consiste en cambiar sistemáticamente la estructura de los vecindarios, con el fin de poder escapar de óptimos locales en los cuales se quede estancado. Básicamente, el proceso consiste en obtener una solución $s'$ nueva del vecindario de la actual $s^{*}$. Luego, a partir del vecindario de $s'$ se ejecuta una búsqueda local hasta alcanzar un nuevo óptimo. Si este último es mejor que $s^{*}$, lo reemplaza. En caso contrario, modifica la estructura del vecindario. \\

Ganando el primer lugar \cite{2012ROADEFresults} del desafío de la ROADEF/EURO el 2012, Buljubasic et al. \cite{gavranovic2012variable}, proponen un método híbrido, consistente en la realización de una búsqueda local, originando los vecindarios $s'$ de soluciones en base a la realización de cuatro tipos de movimientos (en el orden en que están presentados más abajo), a partir de una solución inicial $s$ y así encontrar una mejor asignación. Se pone especial énfasis en que el costo más importante de la solución es el de carga, por lo que los procesos de mayor tamaño (atributo definido en función del total de requerimientos considerando todos los recursos), son los primeros en ser reasignados.
Movimientos:
\begin{itemize}
	\item \textbf{\emph{BPR}}: Se mueve un proceso $p$ a una máquina $m$ y desplazando algunos procesos desde esta a otras máquinas. Movimiento especialmente útil para la resignación de procesos grandes.
	\item \textbf{\emph{Shift}}: Se desplaza un proceso $p$ desde una máquina a otra.
	\item \textbf{\emph{Swap}}:	Intercambio de la asignación de dos procesos, originalmente asignados a dos máquinas distintas.
	\item \textbf{\emph{Chain}}: Se desplazan simultáneamente $l$ procesos $p_1, p_2, ... p_l$ de tal forma que:
		\begin{align}
			s'(p_k) &= s(p_{k+1}) \; k \in \{1,2,3,...,l-1\} \nonumber \\
			s'(p_l) &= s(p_0) \nonumber
		\end{align}
\end{itemize}
Para el proceso de diversificación, es decir, explorar otras zonas del espacio de búsqueda y así obtener soluciones de mejor calidad, se genera ruido o \textit{noise} sobre la función objetivo, eligiendo un recurso $r$ e incrementando su ponderación o peso de costo de carga, creando una función objetivo modificada. El proceso global se repite hasta que límite del tiempo de ejecución termine o se obtenga un mínimo de mejora en la asignación. Según los autores, las máquinas y procesos elegidas en las primeras etapas de ejecución del algoritmo, inciden de gran manera en la calidad final de la solución. Se pone hincapié en que la posibilidad de poder construir una solución desde cero, y no partiendo desde una inicial como lo establece el problema original, permitiría obtener mejores resultados en el proceso de búsqueda local.\\

\subsubsection{Bin Packing}
En Gabay et al. \cite{gabay2013variable}, proponen una solución basada en la heurística Variable size vector bin packing (VSVBP), generalización del Vector Bin Packing y este a su vez, una generalización del Bin Packing, donde el objetivo es cargar una serie ítemes (procesos) dentro de ciertos recipientes (máquinas), de tal forma que el empaque de cada uno de estos sea factible con respecto a determinadas restricciones, ya sea límites de capacidad o balanceo, optimizando alguna función objetivo, como por ejemplo el número de recipientes utilizados. En el caso de VBP, los tamaños de los ítemes son representados por un vector d-dimensional (requerimientos tipo de recurso) y en el caso de VSVBP, los recipientes además tienen su propio vector de capacidades (para cada tipo de recurso). El problema VSVBP es considerado un subproblema del \mrp\, considerando para este último como adicionales, las restricciones de conflicto, uso transitorio, de dispersión y de dependencia. Este método se centra principalmente en la factibilidad más que en la optimilidad de las soluciones, de tal forma que se utilicen como input inicial para heurísticas de búsqueda local. \\


\subsubsection{Acercamientos híbridos}
Cuando se habla de acercamientos híbridos, se refiere a la combinación de las ventajas de varios métodos de optimización combinatorial en un solo algoritmo.\\

Obteniendo el tercer lugar en la ROADEF/EURO 2012, Jaśkowski et al. \cite{jaskowskihybrid}, proponen una técnica híbrida compuesta potencialmente de 2 partes (puede realizarse una de las dos o ambas). En la primera, a partir de una asignación inicial, se realiza una búsqueda local basada en Hill-Climbing, generando los vecindarios de soluciones en base al desplazamiento de un proceso desde una máquina a otra distinta. El Hill-Climbing acepta la primera mejora que encuentra. Si no se encuentra una mejor solución en el vecindario, el algoritmo termina. Con este método se provee de una forma rápida de conseguir soluciones de calidad aceptable. El Hill-Climbing además, mantiene una lista tabú, donde se encuentran las máquinas que han sido utilizadas para el desplazamiento de los procesos. En la segunda parte del algoritmo, el desarrollo se basa en un procedimiento LNS. Se selecciona iterativamente un subproblema más pequeño que el original, escogiendo el subconjunto de máquinas de forma aleatoria o según el nivel de mejora en el costo de la solución que producen. Posteriormente, mediante un modelo MIP (\emph{Mixed integer programmming}), se utiliza un solver como el CPLEX de IBM, para obtener una nueva solución de mejor calidad. Sobre esta última, es posible aplicar nuevamente Hill-Climbing. Según los resultados provistos en \cite{jaskowskihybrid}, la mejor combinación del algoritmo es HC-LNS-HC, es decir, aplicar primero Hill-Climbing, luego LNS con selección de subproblemas basados en una heurística de mejora optimista, para finalmente culminar con un nuevo Hill-Climbing. \\

Otro algoritmo híbrido es GENEPI, propuesto el 2014 por Saber et al. \cite{saber2014genepi}, el cual concibe al \mrp\ como un problema multi-objetivo, definiendo tres metas para el problema original: confiabilidad, basada en el castigo que se da a las asignaciones que sobrecargan a las máquinas; migración, relativo a la penalización de las asignaciones que mueven en demasía los procesos, especialmente a lugares remotos; y electricidad, relativo a obtener las asignaciones minimicen el consumo de electricidad por parte del \textit{Data Center}. La cuantificación de esta última, se realiza en base a la utilización de ciertas constantes de consumo y costo de electricidad, sobre las máquinas que se encuentran en funcionamiento. El algoritmo propiamente tal, se divide en la aplicación de tres diferentes técnicas. Primero se aplica una adaptación de la metaheurística GRASP. Esta última significa  Greedy Randomized Adaptive Search Procedures (GRASP) y fue propuesta por Resende et al. \cite{resende1995grasp}, consiste en un método iterativo de dos fases, donde primero se construye una solución factible. Si no lo es, se implementa un proceso reparador para alcanzar la factibilidad. Si esta última no puede ser lograda, la solución se descarta y se crea una nueva. Una vez lograda la factibilidad, se pasa a la segunda fase, donde a partir de un proceso de búsqueda local se explora el vecindario para encontrar una mejor solución. Durante el transcurso de las iteraciones, se guarda la mejor solución encontrada. donde en cada iteración los procesos son ordenados según sus dependencias y requerimientos, para luego reasignar una determinada fracción de procesos a máquinas distintas a las iniciales y seleccionar aleatoriamente una máquina de entre las factibles y más útiles. El objetivo con la aplicación de GRASP es encontrar soluciones de forma rápida, ya sean de buena o mala calidad, para servir como semillas para la aplicación de la siguiente técnica. En segundo lugar se aplica un algoritmo genético llamado Non-dominated Sorting Genetic Algorithm-II (NSGA-II), donde el operador de cruzamiento se aplica sobre los servicios con tal de minimizar las violaciones de las restricciones de dependencia. El operador de mutación es la reasignación de un proceso a una máquina factible. El objetivo de esta segunda etapa es encontrar una gran cantidad de buenas soluciones, explorando la mayor parte del espacio de búsqueda. Finalmente, se aplica un proceso de búsqueda local, calculando los vecindarios usando operadores \textit{swap}, para intercambiar la asignación de las máquinas de dos procesos, \textit{1-exchange} para mover un proceso de una máquina a otra, y \textit{shift}, para mover un proceso a otra máquina perteneciente al mismo servicio.

\subsubsection{Iterated Local Search}
Lopes et al. \cite{lopes2015heuristics}, proponen una representación basada en MIP utilizando una heurística de tipo \textit{Iterated Local Search} (ILS), para búsqueda de mejores soluciones. ILS toma una solución inicial $s^{*}$ a la cual realiza pequeños cambios o perturbaciones para generar una nueva solución $s'$. Luego aplica búsqueda local sobre $s'$ para producir un nuevo óptimo local ${s'}^{*}$. Esta ultima reemplazará a $s^{*}$  si es mejor de acuerdo algún criterio de aceptación. El proceso se repite hasta que se cumpla alguna condición de término. Respecto de las perturbaciones, estas no deben ser muy pequeñas, con tal de generar buenos niveles de exploración, pero tampoco muy grandes como para permitir el explotar la información de las iteraciones anteriores. \\
En el caso de \cite{lopes2015heuristics}, se utilizan dos tipos de ILS, según la forma en que se genera el vecindario de soluciones:
\begin{itemize}
	\item \textbf{\textit{Heurísticas ILS no restringidas}:}
		\begin{itemize}
			\item \textit{Shift}: Se genera y explora el vecindario completo de soluciones, producto del desplazamiento de cada uno de los procesos a cada máquina, evaluando el costo de todos.
			\item \textit{Swap}: Se genera y explora el vecindario completo de soluciones, producto del intercambio realizado entre cada par de procesos.
		\end{itemize}
	\item \textbf{\textit{Heurísticas ILS restringidas}:} En la búsqueda de la eficiencia y considerando que las instancias del desafío de la ROADEF/EURO podían ser considerablemente grandes, se proponen los siguientes métodos de exploración, que poseen una menor tiempo de ejecución:
		\begin{itemize}
			\item \textit{Shift machine load sort}: Se evalúa un subconjunto de las soluciones originidas con el \emph{shift}. Los vecinos que podrían originar menores costos son evaluados primero.
			\item \textit{Swap in service}:	Para una solución $s$, define un vecindario compuesto por las soluciones que difieren de $s$ por el intercambio de máquina de dos procesos que pertenecen al mismo servicio.
			\item \textit{Restricted swap}: Se evalúa un subconjunto del vecindario de soluciones originadas por \emph{swap}. Para realizar el intercambio, solo se seleccionan los procesos que han cambiado de máquinas en la solución perturbada del ILS.
		\end{itemize}
\end{itemize}
Se definen cuatro tipos de movimientos para realizar las perturbaciones:
el primero, basado en un movimiento de $k-shift$, donde a partir de una solución $s$, se genera su vecindario realizando $k$ movimientos sucesivos de desplazamiento, para luego seleccionar una solución $s'$ aleatoria; un segundo, que se basa en seleccionar un subconjunto de las máquinas de forma aleatoria, construyendo un MRP similar al original, para luego obtener una solución $s'$, utilizando una estrategia de ramificación y poda usando el solver CPLEX; un tercero, llamado ``\textit{k-swap in service}'', seleccionando una solución $s'$ de forma aleatoria, desde el vecindario originado al realizar k sucesivos \text{swap in service}; y el último llamado ``\textit{restricted IP perturbation}'', también basada en crear un MRP a partir de la selección aleatoria de un subconjunto de máquinas, pero esta vez seleccionando también el vecindario del cual se extraerán tales máquinas, de forma aleatoria.
Los experimentos computacionales mostraron que, la combinación de perturbación y búsqueda local, que dieron mejores resultados fue la de \textit{restricted IP perturbation} con heurísticas ILS restringidas. Esta combinación obtuvo el lugar 14 en la ROADEF/EURO 2012. \\

Otra solución basada en ILS, es la propuesta por Mason et al. \cite{masson2013iterated}, donde iterativamente se realiza una búsqueda local a partir de una solución factible inicial. Se selecciona un subconjunto de máquinas, donde a cada miembro $m$ de este se evalúan dos tipos de movimientos. El que presente la mayor efectividad en mejorar la solución actual, es el que será realizado. El primero de ellos se basa en originar el vecindario de soluciones que se obtiene a partir de re-localizar un proceso desde una máquina $m$ a otra distinta. El segundo de los movimientos, se basa en originar el vecindario de soluciones que se obtiene al intercambiar uno o dos procesos de $m$ con otros pertenecientes a otras máquinas. En función de la eficiencia y dado que las instancias de los problemas pueden ser muy grandes (50000 procesos y 5000 máquinas), solo se explora una fracción aleatoria de los vecindarios originados, en ambos movimientos.
Respecto de las perturbaciones, propias de la metaheurística ILS, se cuentan con dos versiones. La primera de ellas es el \textit{home relocate}, donde un subconjunto aleatorio de procesos son re-localizados a su máquina inicial, con el fin de reducir el costo por movimiento de procesos. El otro tipo de perturbación es el \textit{k-swap}, que aleatoriamente selecciona durante cierto número de veces, un par de máquinas desde las cuales se intercambian grupos aleatorios de procesos. Estas perturbaciones o \textit{shaking moves} tienen la función de hacer escapar de ``valles'' u óptimos locales, desde donde se quede estancado el algoritmo. Si no se observan mejoras significativas respecto de las iteraciones anteriores, se aplicará un \textit{Restart}. Los resultados obtenidos de las pruebas computacionales indican que la calidad de las soluciones provistas por el algoritmo, son de un alto nivel, donde en 21 de 30 instancias testeadas, el 99\% de las posibles mejoras son alcanzadas. \\

\subsubsection{Simulated Annealing}

El trabajo de Portal et al. \cite{portal2015sa}, desarrolló un algoritmo basado en la metaheurística \textit{Simulated Annealing} (SA), basada en principios de búsqueda local aplicados iterativamente. Permite la aceptación de soluciones nuevas, que empeoran el valor de la función objetivo, pero de una forma probabilista, con el fin de poder escapar a  óptimos locales. El SA propuesto utiliza dos tipos de movimientos para generar los vecindarios. El primero es un \textit{shift}, moviendo un proceso de una máquina a otra. El segundo es un \textit{swap}, intercambiando dos procesos en máquinas distintas. Para el SA, se comienza con una temperatura $t_0$ que se mantiene constante por $n$ iteraciones y luego se reduce en una proporción $r$. Si la mejor solución encontrada no genera una optimización en su valor dentro de $20n$ iteraciones y el número de de movimientos aceptados es menor al 0,1\%, se aumenta la temperatura para generar la suficiente perturbación como para escapar del óptimo local y aumentar la exploración. Según los resultados reportados de los experimentos computacionales, con pruebas hechas sobre el dataset de instancias oficial del desafío, se buenos resultados  para las versiones A de instancias y comportándose de forma robusta para las instancias B, que eran la de mayor tamaño.

\end{document}




